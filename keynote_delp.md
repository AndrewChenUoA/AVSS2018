---
layout: single
permalink: /keynote_delp
---
**Professor Edward J. Delp**<br/>
Purdue University, USA<br/>
<img src="/assets/images/edward_delp.jpg" style="float:left;padding-right:25px;padding-top:7px;max-width:200px" alt="Professor Edward Delp"/>
<b>Precision Farming: The Other Surveillance Problem</b><br/>
ABSTRACT. In this talk I will describe recent work in image-based plant phenotyping. Estimating the properties of plants (i.e., phenotyping) is critical to predict its viability and biomass. I will describe work in estimating phenotypic traits such as plant locations, number of plants per plot, Leaf Area Index, canopy cover, leaf length and width, and the 
number of leaves per plant. I discuss field-based image acquisition using UAVs and ground-based sensing. I will discuss how this area have many important problems that can be addressed by the computer vision and surveillance communities. The goal is to develop a set of tools to precisely and quickly phenotype hundreds of thousands of plants on a daily basis.

ABOUT THE AUTHOR:<br/>
Edward J. Delp is the Charles William Harrison Distinguished Professor of Electrical and Computer Engineering and Professor of Biomedical Engineering at Purdue University. His research interests include image and video processing, image analysis, computer vision, image and video compression, multimedia security, medical imaging, multimedia systems, communication and information theory. Dr. Delp is a Fellow of the IEEE, a Fellow of the SPIE, a Fellow of the Society for Imaging Science and Technology (IS&T), and a Fellow of the American Institute of Medical and Biological Engineering. In 2004 Dr. Delp received the Technical Achievement Award from the IEEE Signal Processing Society for his work in image and video compression and multimedia security. In 2008 he received the Society Award from IEEE Signal Processing Society (SPS). In 2016 Dr. Delp received the Purdue College of Engineering Mentoring Award for his work in mentoring junior faculty and women graduate students.<br/><br/>
